{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Trading\n",
    "\n",
    "This notebook is a skeleton for paper trading.  See issue https://github.com/CAMPSMITH/sabot/issues/10\n",
    "\n",
    "\n",
    "## Assumptions\n",
    "* there is an external wallet\n",
    "* there is an external provider of data\n",
    "* there is an external machine learning model (inference engine) that provides prediction / decision from \n",
    "* this program will be periodically invoked by a scheduler\n",
    "\n",
    "## Design\n",
    "on invocation\n",
    "1 - get data for prediction\n",
    "2 - get prediction / decision from machine learning model (inference engine)\n",
    "4 - if trade is indicated\n",
    "5 - get balance from wallet\n",
    "6 - if funds available, execute trade\n",
    "7 - if purchase executed, deduct wallet\n",
    "8 - if sale executed, increment wallet\n",
    "\n",
    "how much to transact in each trade (25%) of wallet?\n",
    "amount adjustment for short position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: refactor into library file\n",
    "# TODO: implement wallet in DDB\n",
    "\n",
    "# The following is a facade for the wallet\n",
    "class Wallet():\n",
    "\n",
    "  def __init__(self, initial_balances):\n",
    "        self.balances = {}\n",
    "        for initial_balance in initial_balances:\n",
    "            self.balances[initial_balance['currency']] = initial_balance['currency']\n",
    "    \n",
    "  def get_balances():\n",
    "    return self.balances\n",
    "\n",
    "  def __str__(self):\n",
    "    for balance in self.balances:\n",
    "        return f\"Current {balance['currency']} balance is  {balance['amount']}\"\n",
    "\n",
    "  def add(self,currency,amount):\n",
    "    if currency in self.balances:\n",
    "        self.balances[currency] = {\n",
    "            \"currency\": currency,\n",
    "            \"amount\":self.balances[currency]['amount'] + amount\n",
    "        }   \n",
    "    else:\n",
    "        raise Exception(f\"{currency} is not a valid currency\")\n",
    "\n",
    "  def withdraw(self,currency,amount):\n",
    "    if currency in self.balances:\n",
    "        self.balances[currency] = {\n",
    "            \"currency\": currency,\n",
    "            \"amount\":self.balances[currency]['amount'] - amount\n",
    "        }\n",
    "    else:\n",
    "        raise Exception(f\"{currency} is not a valid currency\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement this\n",
    "\n",
    "def get_trading_data():\n",
    "    # return data needed to get a prediction from inference engine\n",
    "    # should be properly scaled to make prediction\n",
    "    return {} \n",
    "\n",
    "def get_prediction():\n",
    "    return 1 # return data needed to get a prediction from inference engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated paper trade\n",
    "\n",
    "def run():\n",
    "    # this method is called by the scheduler to run this process\n",
    "    get_trading_data() # gets the data needed to make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable functions to create signals for ML training\n",
    "\n",
    "# TODO: these will need to be refactored based on the shape of the dataframe\n",
    "# TODO: refactor these functions to library file\n",
    "# create helper methods to facilitate assessing permutations\n",
    "\n",
    "def make_signals_df(short_window,long_window):\n",
    "    # Filter the date index and close columns\n",
    "    signals_df = ohlcv_df.loc[:, [\"close\"]]\n",
    "\n",
    "    # Use the pct_change function to generate  returns from close prices\n",
    "    signals_df[\"Actual Returns\"] = signals_df[\"close\"].pct_change()\n",
    "\n",
    "    # Generate the fast and slow simple moving averages (4 and 100 days, respectively)\n",
    "    signals_df['SMA_Fast'] = signals_df['close'].rolling(window=short_window).mean()\n",
    "    signals_df['SMA_Slow'] = signals_df['close'].rolling(window=long_window).mean()\n",
    "    \n",
    "    # Drop all NaN values from the DataFrame\n",
    "    signals_df = signals_df.dropna()\n",
    "    \n",
    "    # Initialize the new Signal column\n",
    "    signals_df['Signal'] = 0.0\n",
    "\n",
    "    # When Actual Returns are greater than or equal to 0, generate signal to buy stock long\n",
    "    signals_df.loc[(signals_df['Actual Returns'] >= 0), 'Signal'] = 1\n",
    "\n",
    "    # When Actual Returns are less than 0, generate signal to sell stock short\n",
    "    signals_df.loc[(signals_df['Actual Returns'] < 0), 'Signal'] = -1    \n",
    "    \n",
    "    # Calculate the strategy returns and add them to the signals_df DataFrame\n",
    "    signals_df['Strategy Returns'] = signals_df['Actual Returns'] * signals_df['Signal'].shift()\n",
    "    \n",
    "    return signals_df\n",
    "\n",
    "def create_train_test_datasets(months):\n",
    "    # calculate the trainind start and end based on the given training months\n",
    "    training_begin = X.index.min()\n",
    "    training_end = X.index.min() + DateOffset(months=months)\n",
    "\n",
    "    # create the training features dataset X_train and training classigication labels y_train for the training timeframe\n",
    "    X_train = X.loc[training_begin:training_end]\n",
    "    y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "    # create the testing features dataset X_test and testing classigication labels y_test following the training timeframe\n",
    "    X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "    y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "    \n",
    "    # Use StandardScaler to scale the data.\n",
    "    # Scale the features DataFrames\n",
    "\n",
    "    # Create a StandardScaler instance\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Apply the scaler model to fit the X-train data\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "\n",
    "    # Transform the X_train and X_test DataFrames using the X_scaler\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)  \n",
    "    return X_train_scaled, y_train, X_test_scaled, y_test\n",
    "\n",
    "def get_predictions(model,X_train_scaled,y_train,X_test_scaled):\n",
    "    \n",
    "    # Fit the model using the training data\n",
    "    model = model.fit(X_train_scaled,y_train)\n",
    "\n",
    "    # Use the testing dataset to generate the predictions for the new model\n",
    "    # store these in disctionary associated with the model architecture being evaluated\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "\n",
    "    return predictions\n",
    "    \n",
    "def backtest_model(model_name, y_test, y_predictions, actual_returns):\n",
    "    \n",
    "    # Use a classification report to evaluate the model using the predictions and testing data\n",
    "    model_classification_report = classification_report(y_test, y_predictions)\n",
    "\n",
    "    # Backtest model performance\n",
    "\n",
    "    # Create a new empty predictions DataFrame.\n",
    "    # Create a predictions DataFrame\n",
    "    df=pd.DataFrame(index=y_test.index)\n",
    "\n",
    "    # Add the alternate model predictions to the DataFrame\n",
    "    df['Predicted'] = y_predictions\n",
    "\n",
    "    # Add the actual returns to the DataFrame\n",
    "    df['Actual Returns'] = actual_returns\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Add the strategy returns to the DataFrame\n",
    "    df['Strategy Returns'] = (df['Actual Returns'] * df['Predicted'])\n",
    "\n",
    "    # Calculate the cumulative stategy return\n",
    "    df['strategy_cum_return'] = (1 + df[\"Strategy Returns\"]).cumprod()\n",
    "\n",
    "    # Calculate the actual stategy return\n",
    "    df['actual_cum_return'] = (1 + df[\"Actual Returns\"]).cumprod()\n",
    "\n",
    "#     # Plot the actual returns versus the strategy returns\n",
    "#     cum_actual_strategy_plot = df[['actual_cum_return','strategy_cum_return']].plot(\n",
    "#         figsize=(15,7),\n",
    "#         title=f'Cumulative Returns Actual vs Strategy for model {model_name}'\n",
    "#     )\n",
    "#     # save plot\n",
    "#     cum_actual_strategy_plot.figure.savefig(f'images/{model_name}_actual_vs_strategy_cum_returns.png', bbox_inches='tight')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main loop\n",
    "# TODO: Modify to fit data and looping needs\n",
    "\n",
    "models = {}\n",
    "# construct the model permutations and evaluate the model permutations\n",
    "for name in alternate_models:\n",
    "    returns = None\n",
    "    max_return = 0\n",
    "    selected_model = None\n",
    "    for training_months in training_dataset_months:\n",
    "        for short_window_size in short_window_sizes:\n",
    "            for long_window_size in long_window_sizes:\n",
    "                # create a key for this model permutation\n",
    "                model_key = f\"{name}-tr({training_months})-sw({short_window_size})-lw({long_window_size})\"\n",
    "                \n",
    "                # configure model permutation\n",
    "                models[model_key] = {\n",
    "                    \"model_name\":name,\n",
    "                    \"training_months\":training_months,\n",
    "                    \"short_window_size\":short_window_size,\n",
    "                    \"long_window_size\":long_window_size,\n",
    "                    \"model\":alternate_models[name][\"model\"],\n",
    "                }\n",
    "                \n",
    "                # create the signals data set with the actual returns, fast and slow SMA, signal and strategy returns\n",
    "                models[model_key]['signals_df'] = make_signals_df(short_window_size,long_window_size)\n",
    "\n",
    "                # create training and testing datasets\n",
    "                models[model_key]['X_train_scaled'], models[model_key]['y_train'], models[model_key]['X_test_scaled'], models[model_key]['y_test'] = create_train_test_datasets(training_months)\n",
    "\n",
    "                # get predictions\n",
    "                models[model_key]['y_predictions'] =  get_predictions(\n",
    "                    models[model_key]['model'], \n",
    "                    models[model_key]['X_train_scaled'], \n",
    "                    models[model_key]['y_train'], \n",
    "                    models[model_key]['X_test_scaled'])\n",
    "\n",
    "                # Classification reports\n",
    "                models[model_key]['classification_report'] = classification_report( models[model_key]['y_test'], models[model_key]['y_predictions'])\n",
    "\n",
    "                # Print the classification report\n",
    "                print(f\"\"\"\n",
    "                {model_key} classification report: \n",
    "                ---------------------------------------------------------------------------\n",
    "                {models[model_key]['classification_report']}\n",
    "                ---------------------------------------------------------------------------\n",
    "                \"\"\")                \n",
    "\n",
    "                # backtest model\n",
    "                models[model_key]['backtest'] = backtest_model(\n",
    "                    model_key,\n",
    "                    models[model_key]['y_test'],\n",
    "                    models[model_key]['y_predictions'],\n",
    "                    models[model_key]['signals_df'].loc[models[model_key]['y_test'].index.min():,'Actual Returns'],\n",
    "                )   \n",
    "                \n",
    "                # add the cumulative return to the list of returns for plotting\n",
    "                # add the actual and signal returns if the \n",
    "                if returns is None:\n",
    "                    # This is the permutation for the model\n",
    "                    # create the returns dataframe and add the actual returns and the signal returns\n",
    "                    returns = {\n",
    "                        \"actual\": (1 + models[model_key]['signals_df']['Actual Returns']).cumprod(),\n",
    "                        \"signal\": (1 + models[model_key]['signals_df']['Strategy Returns']).cumprod()\n",
    "                    }\n",
    "                returns[model_key] = models[model_key]['backtest']['strategy_cum_return']\n",
    "                if returns[model_key].iloc[-1] > max_return:\n",
    "                    max_return = returns[model_key].iloc[-1]\n",
    "                    selected_model = model_key\n",
    "                    \n",
    "    # create a plot for the family of returns for the range of training monts, and SMA window sizes\n",
    "    returns_df = pd.DataFrame(returns)\n",
    "    model_family_plot = returns_df.plot(\n",
    "        figsize=(15,15),\n",
    "        title=f'{name} Cumulative Returns for various training and SMA window sizes'\n",
    "    )\n",
    "    \n",
    "    # save plot\n",
    "    model_family_plot.figure.savefig(f'images/{name}_returns.png', bbox_inches='tight')\n",
    "\n",
    "    # show the final returns for the family\n",
    "    display(returns_df.iloc[-1:,:].T)\n",
    "\n",
    "    # show the max return achieved with the model\n",
    "    print(f\"maximum cumulative return for {name} models was {max_return} from model permutation {selected_model}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e9706e2b979a409812944fd4a0384c92c020042a42e01b3b75954b474c5de965"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
